{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14148823,"sourceType":"datasetVersion","datasetId":9017324},{"sourceId":14152111,"sourceType":"datasetVersion","datasetId":9019899}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision timm --quiet\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:51:26.512806Z","iopub.execute_input":"2025-12-14T15:51:26.513048Z","iopub.status.idle":"2025-12-14T15:52:37.862254Z","shell.execute_reply.started":"2025-12-14T15:51:26.513029Z","shell.execute_reply":"2025-12-14T15:52:37.861359Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Kaggle already has torch & torchvision installed correctly\n!pip install timm --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:52:42.396004Z","iopub.execute_input":"2025-12-14T15:52:42.396292Z","iopub.status.idle":"2025-12-14T15:52:45.584962Z","shell.execute_reply.started":"2025-12-14T15:52:42.396263Z","shell.execute_reply":"2025-12-14T15:52:45.584173Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"**Srat Here**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import datasets, transforms, models\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:52:56.726258Z","iopub.execute_input":"2025-12-14T15:52:56.727024Z","iopub.status.idle":"2025-12-14T15:53:02.894141Z","shell.execute_reply.started":"2025-12-14T15:52:56.726993Z","shell.execute_reply":"2025-12-14T15:53:02.893519Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train_tf = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(0.3, 0.3, 0.3, 0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\nval_tf = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:53:25.019096Z","iopub.execute_input":"2025-12-14T15:53:25.019976Z","iopub.status.idle":"2025-12-14T15:53:25.025087Z","shell.execute_reply.started":"2025-12-14T15:53:25.019948Z","shell.execute_reply":"2025-12-14T15:53:25.024285Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset_root = \"/kaggle/input/caltech/caltech-101/101_ObjectCategories/101_ObjectCategories\"\n\nfull_dataset = datasets.ImageFolder(dataset_root)\n\nbg_idx = full_dataset.class_to_idx.get(\"BACKGROUND_Google\", None)\n\nvalid_indices = [\n    i for i, (_, y) in enumerate(full_dataset.samples)\n    if y != bg_idx\n]\n\nclass_map = {}\nnew_idx = 0\nfor cls, old_idx in full_dataset.class_to_idx.items():\n    if cls != \"BACKGROUND_Google\":\n        class_map[old_idx] = new_idx\n        new_idx += 1\n\nclass_names = [\n    cls for cls in full_dataset.classes if cls != \"BACKGROUND_Google\"\n]\n\nclass CaltechDataset(Dataset):\n    def __init__(self, base_dataset, indices, transform):\n        self.base = base_dataset\n        self.indices = indices\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, idx):\n        img, label = self.base[self.indices[idx]]\n        img = self.transform(img)\n        label = class_map[label]\n        return img, label\n\ntrain_size = int(0.8 * len(valid_indices))\nval_size = len(valid_indices) - train_size\n\ntrain_idx, val_idx = random_split(valid_indices, [train_size, val_size])\n\ntrain_ds = CaltechDataset(full_dataset, train_idx, train_tf)\nval_ds = CaltechDataset(full_dataset, val_idx, val_tf)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n\nnum_classes = len(class_names)\nprint(\"Classes:\", num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:53:38.676304Z","iopub.execute_input":"2025-12-14T15:53:38.676869Z","iopub.status.idle":"2025-12-14T15:53:54.736576Z","shell.execute_reply.started":"2025-12-14T15:53:38.676845Z","shell.execute_reply":"2025-12-14T15:53:54.735831Z"}},"outputs":[{"name":"stdout","text":"Classes: 101\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n\n# Freeze backbone\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:53:59.758292Z","iopub.execute_input":"2025-12-14T15:53:59.758882Z","iopub.status.idle":"2025-12-14T15:54:00.484157Z","shell.execute_reply.started":"2025-12-14T15:53:59.758857Z","shell.execute_reply":"2025-12-14T15:54:00.483582Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 197MB/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n\ndef train_epoch(loader):\n    model.train()\n    total, correct, loss_sum = 0, 0, 0\n\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n\n        optimizer.zero_grad()\n        out = model(x)\n        loss = criterion(out, y)\n        loss.backward()\n        optimizer.step()\n\n        loss_sum += loss.item() * x.size(0)\n        correct += (out.argmax(1) == y).sum().item()\n        total += y.size(0)\n\n    return loss_sum / total, correct / total\n\nfor epoch in range(8):\n    loss, acc = train_epoch(train_loader)\n    print(f\"[Classifier] Epoch {epoch+1} - Loss: {loss:.4f} Acc: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:54:30.272204Z","iopub.execute_input":"2025-12-14T15:54:30.272722Z","iopub.status.idle":"2025-12-14T15:59:45.721529Z","shell.execute_reply.started":"2025-12-14T15:54:30.272695Z","shell.execute_reply":"2025-12-14T15:59:45.720722Z"}},"outputs":[{"name":"stdout","text":"[Classifier] Epoch 1 - Loss: 2.3517 Acc: 0.5202\n[Classifier] Epoch 2 - Loss: 0.9941 Acc: 0.7881\n[Classifier] Epoch 3 - Loss: 0.7003 Acc: 0.8440\n[Classifier] Epoch 4 - Loss: 0.5660 Acc: 0.8644\n[Classifier] Epoch 5 - Loss: 0.5034 Acc: 0.8755\n[Classifier] Epoch 6 - Loss: 0.4339 Acc: 0.8908\n[Classifier] Epoch 7 - Loss: 0.4002 Acc: 0.8973\n[Classifier] Epoch 8 - Loss: 0.3654 Acc: 0.9040\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for param in model.layer4.parameters():\n    param.requires_grad = True\n\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\nfor epoch in range(10):\n    loss, acc = train_epoch(train_loader)\n    print(f\"[Fine-tune] Epoch {epoch+1} - Loss: {loss:.4f} Acc: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:03:47.502716Z","iopub.execute_input":"2025-12-14T16:03:47.503055Z","iopub.status.idle":"2025-12-14T16:10:05.703882Z","shell.execute_reply.started":"2025-12-14T16:03:47.503027Z","shell.execute_reply":"2025-12-14T16:10:05.703076Z"}},"outputs":[{"name":"stdout","text":"[Fine-tune] Epoch 1 - Loss: 0.2589 Acc: 0.9255\n[Fine-tune] Epoch 2 - Loss: 0.1514 Acc: 0.9568\n[Fine-tune] Epoch 3 - Loss: 0.1101 Acc: 0.9719\n[Fine-tune] Epoch 4 - Loss: 0.0896 Acc: 0.9735\n[Fine-tune] Epoch 5 - Loss: 0.0729 Acc: 0.9817\n[Fine-tune] Epoch 6 - Loss: 0.0549 Acc: 0.9867\n[Fine-tune] Epoch 7 - Loss: 0.0628 Acc: 0.9839\n[Fine-tune] Epoch 8 - Loss: 0.0483 Acc: 0.9869\n[Fine-tune] Epoch 9 - Loss: 0.0448 Acc: 0.9872\n[Fine-tune] Epoch 10 - Loss: 0.0338 Acc: 0.9922\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"torch.save({\n    \"model\": model.state_dict(),\n    \"classes\": class_names\n}, \"resnet18_caltech101_generalized.pth\")\n\nprint(\"Model saved ✅\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:10:14.261418Z","iopub.execute_input":"2025-12-14T16:10:14.261759Z","iopub.status.idle":"2025-12-14T16:10:14.335867Z","shell.execute_reply.started":"2025-12-14T16:10:14.261731Z","shell.execute_reply":"2025-12-14T16:10:14.335230Z"}},"outputs":[{"name":"stdout","text":"Model saved ✅\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom PIL import Image\n\n# -------------------------\n# Device\n# -------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n# -------------------------\n# Load trained model\n# -------------------------\ncheckpoint = torch.load(\n    \"resnet18_caltech101_generalized.pth\",\n    map_location=device\n)\n\nclass_names = checkpoint[\"classes\"]\nnum_classes = len(class_names)\n\nmodel = models.resnet18(weights=None)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel.load_state_dict(checkpoint[\"model\"])\n\nmodel.to(device)\nmodel.eval()\n\nprint(\"Model loaded successfully\")\nprint(\"Number of classes:\", num_classes)\n\n# -------------------------\n# Image Transform (MUST MATCH TRAINING)\n# -------------------------\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n# -------------------------\n# Prediction Function\n# -------------------------\ndef predict_image(image_path, topk=5):\n    image = Image.open(image_path).convert(\"RGB\")\n    image = transform(image).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        outputs = model(image)\n        probs = torch.softmax(outputs, dim=1)\n        top_probs, top_idxs = probs.topk(topk)\n\n    print(f\"\\nImage: {image_path}\")\n    print(\"Top predictions:\")\n    for p, idx in zip(top_probs[0], top_idxs[0]):\n        print(f\"{class_names[idx]} : {p.item()*100:.2f}%\")\n\n# -------------------------\n# Example Usage\n# -------------------------\npredict_image(\"/kaggle/input/infer-image/CelingFan.jpg\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:10:19.908765Z","iopub.execute_input":"2025-12-14T16:10:19.909527Z","iopub.status.idle":"2025-12-14T16:10:20.259534Z","shell.execute_reply.started":"2025-12-14T16:10:19.909500Z","shell.execute_reply":"2025-12-14T16:10:20.258920Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nModel loaded successfully\nNumber of classes: 101\n\nImage: /kaggle/input/infer-image/CelingFan.jpg\nTop predictions:\nceiling_fan : 100.00%\ndragonfly : 0.00%\nanchor : 0.00%\noctopus : 0.00%\nstarfish : 0.00%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/working\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:10:24.918909Z","iopub.execute_input":"2025-12-14T16:10:24.919164Z","iopub.status.idle":"2025-12-14T16:10:24.923599Z","shell.execute_reply.started":"2025-12-14T16:10:24.919146Z","shell.execute_reply":"2025-12-14T16:10:24.922687Z"}},"outputs":[{"name":"stdout","text":"['resnet18_caltech101_generalized.pth', '.virtual_documents']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# This generates a blue clickable link in the output area below the cell\nFileLink(r'resnet18_caltech101_generalized.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T16:13:13.221818Z","iopub.execute_input":"2025-12-14T16:13:13.222119Z","iopub.status.idle":"2025-12-14T16:13:13.228470Z","shell.execute_reply.started":"2025-12-14T16:13:13.222098Z","shell.execute_reply":"2025-12-14T16:13:13.227685Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/resnet18_caltech101_generalized.pth","text/html":"<a href='resnet18_caltech101_generalized.pth' target='_blank'>resnet18_caltech101_generalized.pth</a><br>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}